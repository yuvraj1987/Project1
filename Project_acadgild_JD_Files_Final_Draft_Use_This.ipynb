{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading file from give url with CSV format. Pandas Dataframe that function\n",
    "import pandas as pd # Pandas Dataframe\n",
    "import numpy as np  # Numpy package \n",
    "import matplotlib.pyplot as plt # Ploting package \n",
    "# Reading csv in pandas DF\n",
    "data_set_1 =pd.read_csv('https://raw.githubusercontent.com/jackiekazil/data-wrangling/master/data/chp3/data-text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Data Row * Columns :\t (4656, 12)\n",
      "Columns Name in Data Set    :\t Index(['Indicator', 'PUBLISH STATES', 'Year', 'WHO region',\n",
      "       'World Bank income group', 'Country', 'Sex', 'Display Value', 'Numeric',\n",
      "       'Low', 'High', 'Comments'],\n",
      "      dtype='object')\n",
      "Top 3 Rows of Data Set      :\t                            Indicator PUBLISH STATES  Year WHO region  \\\n",
      "0   Life expectancy at birth (years)      Published  1990     Europe   \n",
      "1   Life expectancy at birth (years)      Published  2000     Europe   \n",
      "2  Life expectancy at age 60 (years)      Published  2012     Europe   \n",
      "\n",
      "  World Bank income group  Country         Sex  Display Value  Numeric  Low  \\\n",
      "0             High-income  Andorra  Both sexes             77     77.0  NaN   \n",
      "1             High-income  Andorra  Both sexes             80     80.0  NaN   \n",
      "2             High-income  Andorra      Female             28     28.0  NaN   \n",
      "\n",
      "   High  Comments  \n",
      "0   NaN       NaN  \n",
      "1   NaN       NaN  \n",
      "2   NaN       NaN  \n",
      "~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~\n",
      "Data Set information --:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4656 entries, 0 to 4655\n",
      "Data columns (total 12 columns):\n",
      "Indicator                  4656 non-null object\n",
      "PUBLISH STATES             4656 non-null object\n",
      "Year                       4656 non-null int64\n",
      "WHO region                 4656 non-null object\n",
      "World Bank income group    4656 non-null object\n",
      "Country                    4656 non-null object\n",
      "Sex                        4656 non-null object\n",
      "Display Value              4656 non-null int64\n",
      "Numeric                    4656 non-null float64\n",
      "Low                        0 non-null float64\n",
      "High                       0 non-null float64\n",
      "Comments                   0 non-null float64\n",
      "dtypes: float64(4), int64(2), object(6)\n",
      "memory usage: 436.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# printing result which raised in query and other information to view dataset \n",
    "print (\"Shape of Data Row * Columns :\\t\", data_set_1.shape)\n",
    "print (\"Columns Name in Data Set    :\\t\", data_set_1.columns)\n",
    "print (\"Top 3 Rows of Data Set      :\\t\", data_set_1.head(3))\n",
    "print (\"~~*~~\"*10)\n",
    "print (\"Data Set information --:\\n\")\n",
    "print (data_set_1.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another link prvovide in assignment which loaded into pandas df\n",
    "data_set_2 = pd.read_csv(\"https://raw.githubusercontent.com/kjam/data-wrangling-pycon/master/data/berlin_weather_oldest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Data Row * Columns :\t (117208, 21)\n",
      "Columns Name in Data Set    :\t Index(['STATION', 'STATION_NAME', 'DATE', 'PRCP', 'SNWD', 'SNOW', 'TMAX',\n",
      "       'TMIN', 'WDFG', 'PGTM', 'WSFG', 'WT09', 'WT07', 'WT01', 'WT06', 'WT05',\n",
      "       'WT04', 'WT16', 'WT08', 'WT18', 'WT03'],\n",
      "      dtype='object')\n",
      "Top 3 Rows of Data Set      :\t              STATION         STATION_NAME      DATE  PRCP  SNWD  SNOW  TMAX  \\\n",
      "0  GHCND:GME00111445  BERLIN TEMPELHOF GM  19310101    46 -9999 -9999 -9999   \n",
      "1  GHCND:GME00111445  BERLIN TEMPELHOF GM  19310102   107 -9999 -9999    50   \n",
      "2  GHCND:GME00111445  BERLIN TEMPELHOF GM  19310103 -9999 -9999 -9999    28   \n",
      "\n",
      "   TMIN  WDFG  PGTM  ...   WT09  WT07  WT01  WT06  WT05  WT04  WT16  WT08  \\\n",
      "0   -11 -9999 -9999  ...  -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999   \n",
      "1    11 -9999 -9999  ...  -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999   \n",
      "2    11 -9999 -9999  ...  -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999   \n",
      "\n",
      "   WT18  WT03  \n",
      "0 -9999 -9999  \n",
      "1 -9999 -9999  \n",
      "2 -9999 -9999  \n",
      "\n",
      "[3 rows x 21 columns]\n",
      "~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~\n",
      "Data Set information --:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 117208 entries, 0 to 117207\n",
      "Data columns (total 21 columns):\n",
      "STATION         117208 non-null object\n",
      "STATION_NAME    117208 non-null object\n",
      "DATE            117208 non-null int64\n",
      "PRCP            117208 non-null int64\n",
      "SNWD            117208 non-null int64\n",
      "SNOW            117208 non-null int64\n",
      "TMAX            117208 non-null int64\n",
      "TMIN            117208 non-null int64\n",
      "WDFG            117208 non-null int64\n",
      "PGTM            117208 non-null int64\n",
      "WSFG            117208 non-null int64\n",
      "WT09            117208 non-null int64\n",
      "WT07            117208 non-null int64\n",
      "WT01            117208 non-null int64\n",
      "WT06            117208 non-null int64\n",
      "WT05            117208 non-null int64\n",
      "WT04            117208 non-null int64\n",
      "WT16            117208 non-null int64\n",
      "WT08            117208 non-null int64\n",
      "WT18            117208 non-null int64\n",
      "WT03            117208 non-null int64\n",
      "dtypes: int64(19), object(2)\n",
      "memory usage: 18.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# printing result which raised in query and other information to view dataset \n",
    "print (\"Shape of Data Row * Columns :\\t\", data_set_2.shape)\n",
    "print (\"Columns Name in Data Set    :\\t\", data_set_2.columns)\n",
    "print (\"Top 3 Rows of Data Set      :\\t\", data_set_2.head(3))\n",
    "print (\"~~*~~\"*10)\n",
    "print (\"Data Set information --:\\n\")\n",
    "print (data_set_2.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Output for First Data Set :\n",
      "(array([   0,    1,    2, ..., 4653, 4654, 4655], dtype=int64),)\n",
      "Expected Output for Second Data Set :\n",
      "(array([     0,      1,      2, ..., 117205, 117206, 117207], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "# Get the row index number from the above DF \n",
    "import numpy as np\n",
    "print (\"Expected Output for First Data Set :\")\n",
    "print (np.where(data_set_1.Sex !=0))\n",
    "print (\"Expected Output for Second Data Set :\")\n",
    "print (np.where(data_set_2.STATION != \"nan\"))# getting Nan values and result in shown as np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When Column name not renamed permanently :\n",
      "Index(['Indicator', 'PUBLISH STATES', 'Year', 'WHO region',\n",
      "       'World Bank income group', 'Country', 'Sex', 'Display Value', 'Numeric',\n",
      "       'Low', 'High', 'Comments'],\n",
      "      dtype='object')\n",
      "~~*~~*~~~~*~~*~~~~*~~*~~~~*~~*~~~~*~~*~~~~*~~*~~~~*~~*~~~~*~~*~~~~*~~*~~~~*~~*~~\n",
      "Columns name after changes done over One Column\n",
      "Index(['Indicator_id', 'PUBLISH STATES', 'Year', 'WHO region',\n",
      "       'World Bank income group', 'Country', 'Sex', 'Display Value', 'Numeric',\n",
      "       'Low', 'High', 'Comments'],\n",
      "      dtype='object')\n",
      "~~*~~*~~~~*~~*~~~~*~~*~~~~*~~*~~~~*~~*~~~~*~~*~~~~*~~*~~~~*~~*~~~~*~~*~~~~*~~*~~\n",
      "Columns name after changes done over One Column\n",
      "Index(['indicator_id', 'publish_states', 'year', 'who_region',\n",
      "       'world_bank_income_group', 'country', 'sex', 'display_value', 'numeric',\n",
      "       'low', 'high', 'comments'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## Renaming over memory of data frame not changed permanently\n",
    "data_set_1.rename(columns={\"Indicator\":\"Indicator_id\"})\n",
    "print (\"When Column name not renamed permanently :\")\n",
    "print (data_set_1.columns)\n",
    "print (\"~~*~~*~~\"*10)\n",
    "## Renamed permanently of column name\n",
    "data_set_1.rename(columns={\"Indicator\":\"Indicator_id\"},inplace=True)\n",
    "print (\"Columns name after changes done over One Column\")\n",
    "print (data_set_1.columns)\n",
    "print (\"~~*~~*~~\"*10)\n",
    "## Renaming Mulitple Columns \n",
    "data_set_1.columns = data_set_1.columns.str.lower()\n",
    "data_set_1.columns = data_set_1.columns.str.replace(\" \",\"_\")\n",
    "print (\"Columns name after changes done over One Column\")\n",
    "print (data_set_1.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           indicator_id publish_states  year who_region  \\\n",
      "0      Life expectancy at birth (years)      Published  1990     Europe   \n",
      "1270   Life expectancy at birth (years)      Published  1990     Europe   \n",
      "3193   Life expectancy at birth (years)      Published  1990     Europe   \n",
      "3194   Life expectancy at birth (years)      Published  1990     Europe   \n",
      "3197  Life expectancy at age 60 (years)      Published  1990     Europe   \n",
      "\n",
      "     world_bank_income_group              country         sex  display_value  \\\n",
      "0                High-income              Andorra  Both sexes             77   \n",
      "1270             High-income              Germany        Male             72   \n",
      "3193     Lower-middle-income  Republic of Moldova        Male             65   \n",
      "3194     Lower-middle-income  Republic of Moldova  Both sexes             68   \n",
      "3197     Lower-middle-income  Republic of Moldova        Male             15   \n",
      "\n",
      "      numeric  low  high  comments  \n",
      "0        77.0  NaN   NaN       NaN  \n",
      "1270     72.0  NaN   NaN       NaN  \n",
      "3193     65.0  NaN   NaN       NaN  \n",
      "3194     68.0  NaN   NaN       NaN  \n",
      "3197     15.0  NaN   NaN       NaN  \n"
     ]
    }
   ],
   "source": [
    "### Arrange Values of Particular column in Asending Order.\n",
    "Asending_order_df = data_set_1.sort_values(['year'],ascending=True)\n",
    "print (Asending_order_df.head()) # Showing First 5 Record on Shorting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        indicator_id               country  year  \\\n",
      "0   Life expectancy at birth (years)               Andorra  1990   \n",
      "1   Life expectancy at birth (years)               Andorra  2000   \n",
      "2  Life expectancy at age 60 (years)               Andorra  2012   \n",
      "3  Life expectancy at age 60 (years)               Andorra  2000   \n",
      "4   Life expectancy at birth (years)  United Arab Emirates  2012   \n",
      "\n",
      "              who_region publish_states  \n",
      "0                 Europe      Published  \n",
      "1                 Europe      Published  \n",
      "2                 Europe      Published  \n",
      "3                 Europe      Published  \n",
      "4  Eastern Mediterranean      Published  \n"
     ]
    }
   ],
   "source": [
    "### Arrange multiple colums values in ascending order\n",
    "Muliple_columns = data_set_1[[\"indicator_id\",\"country\",\"year\",\"who_region\",\"publish_states\"]]\n",
    "print (Muliple_columns.head()) # Extracted Columns and printed over First 5 Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                country                       indicator_id publish_states  \\\n",
      "0               Andorra   Life expectancy at birth (years)      Published   \n",
      "1               Andorra   Life expectancy at birth (years)      Published   \n",
      "2               Andorra  Life expectancy at age 60 (years)      Published   \n",
      "3               Andorra  Life expectancy at age 60 (years)      Published   \n",
      "4  United Arab Emirates   Life expectancy at birth (years)      Published   \n",
      "\n",
      "   year             who_region world_bank_income_group         sex  \\\n",
      "0  1990                 Europe             High-income  Both sexes   \n",
      "1  2000                 Europe             High-income  Both sexes   \n",
      "2  2012                 Europe             High-income      Female   \n",
      "3  2000                 Europe             High-income  Both sexes   \n",
      "4  2012  Eastern Mediterranean             High-income      Female   \n",
      "\n",
      "   display_value  numeric  low  high  comments  \n",
      "0             77     77.0  NaN   NaN       NaN  \n",
      "1             80     80.0  NaN   NaN       NaN  \n",
      "2             28     28.0  NaN   NaN       NaN  \n",
      "3             23     23.0  NaN   NaN       NaN  \n",
      "4             78     78.0  NaN   NaN       NaN  \n"
     ]
    }
   ],
   "source": [
    "## Make Country as First Column in Data Set Frame \n",
    "List_of_col = data_set_1.columns.tolist() # Getting list of Columns\n",
    "List_of_col.insert(0, List_of_col.pop(List_of_col.index('country'))) # Removed the country from list\n",
    "data_set_1 = data_set_1.reindex(columns= List_of_col) # Reindexing the index\n",
    "print (data_set_1.head()) # First five records printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['Europe', 'Europe', 'Europe', ..., 'Africa', 'Africa', 'Africa'],\n",
      "      dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "## Get the Column array using a variable\n",
    "array_expected =[np.array(data_set_1.who_region)]\n",
    "print (array_expected) # region wise 1-darray as request in Question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         indicator_id publish_states  year       who_region  \\\n",
      "11   Life expectancy at birth (years)      Published  2012           Europe   \n",
      "24  Life expectancy at age 60 (years)      Published  2012  Western Pacific   \n",
      "27  Life expectancy at age 60 (years)      Published  1990         Americas   \n",
      "\n",
      "   world_bank_income_group            country     sex  display_value  numeric  \\\n",
      "11             High-income            Austria  Female             83     83.0   \n",
      "24             High-income  Brunei Darussalam  Female             21     21.0   \n",
      "27             High-income             Canada  Female             24     24.0   \n",
      "\n",
      "    low  high  comments  \n",
      "11  NaN   NaN       NaN  \n",
      "24  NaN   NaN       NaN  \n",
      "27  NaN   NaN       NaN  \n"
     ]
    }
   ],
   "source": [
    "# Get the Subset rows 11,24 and 27\n",
    "row_id = [11,24,27] # give row wise data need to be extracted\n",
    "List_of_col = data_set_1.columns.tolist() # getting list of columns\n",
    "List_of_col.insert(5, List_of_col.pop(List_of_col.index('country'))) # replaceing the country column to 6 postion \n",
    "data_set_1 = data_set_1.reindex(columns= List_of_col) # Re ~ index the column \n",
    "expected_rows_df = pd.DataFrame(data_set_1.loc[x] for x in row_id) # getting / extrated the row requested in question\n",
    "print (expected_rows_df) # printed the rows on screen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         indicator_id publish_states  year  \\\n",
      "0    Life expectancy at birth (years)      Published  1990   \n",
      "1    Life expectancy at birth (years)      Published  2000   \n",
      "3   Life expectancy at age 60 (years)      Published  2000   \n",
      "4    Life expectancy at birth (years)      Published  2012   \n",
      "6   Life expectancy at age 60 (years)      Published  1990   \n",
      "7   Life expectancy at age 60 (years)      Published  2012   \n",
      "9    Life expectancy at birth (years)      Published  2000   \n",
      "10   Life expectancy at birth (years)      Published  2012   \n",
      "11   Life expectancy at birth (years)      Published  2012   \n",
      "13   Life expectancy at birth (years)      Published  2012   \n",
      "\n",
      "               who_region world_bank_income_group               country  \\\n",
      "0                  Europe             High-income               Andorra   \n",
      "1                  Europe             High-income               Andorra   \n",
      "3                  Europe             High-income               Andorra   \n",
      "4   Eastern Mediterranean             High-income  United Arab Emirates   \n",
      "6                Americas             High-income   Antigua and Barbuda   \n",
      "7                Americas             High-income   Antigua and Barbuda   \n",
      "9         Western Pacific             High-income             Australia   \n",
      "10        Western Pacific             High-income             Australia   \n",
      "11                 Europe             High-income               Austria   \n",
      "13                 Europe             High-income               Belgium   \n",
      "\n",
      "           sex  display_value  numeric  low  high  comments  \n",
      "0   Both sexes             77     77.0  NaN   NaN       NaN  \n",
      "1   Both sexes             80     80.0  NaN   NaN       NaN  \n",
      "3   Both sexes             23     23.0  NaN   NaN       NaN  \n",
      "4       Female             78     78.0  NaN   NaN       NaN  \n",
      "6         Male             17     17.0  NaN   NaN       NaN  \n",
      "7   Both sexes             22     22.0  NaN   NaN       NaN  \n",
      "9   Both sexes             80     80.0  NaN   NaN       NaN  \n",
      "10  Both sexes             83     83.0  NaN   NaN       NaN  \n",
      "11      Female             83     83.0  NaN   NaN       NaN  \n",
      "13      Female             83     83.0  NaN   NaN       NaN  \n"
     ]
    }
   ],
   "source": [
    "#Get the subset rows excluding 5,8, 12, 23, and 56\n",
    "row_id_exclude = [2,5,8,12,15,23,56] # these row should be excluded from data frame\n",
    "excluded_rows_df = pd.DataFrame(data_set_1.loc[x] for x in data_set_1.index if x not in row_id_exclude ) #\n",
    "print (excluded_rows_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~\n",
      "User Dataframe Top 5 Rows :- \n",
      "    UserID      User  Gender  Registered   Cancelled\n",
      "0       1   Charles    male  2012-12-21         NaN\n",
      "1       2     Pedro    male  2010-08-01  2010-08-08\n",
      "2       3  Caroline  female  2012-10-23  2016-06-07\n",
      "3       4   Brielle  female  2013-07-17         NaN\n",
      "4       5  Benjamin    male  2010-11-25         NaN\n",
      "~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~\n",
      "Session Dataframe Top 5 Rows :- \n",
      "    SessionID SessionDate  UserID\n",
      "0          1  2010-01-05       2\n",
      "1          2  2010-08-01       2\n",
      "2          3  2010-11-25       2\n",
      "3          4  2011-09-21       5\n",
      "4          5  2011-10-19       4\n",
      "~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~\n",
      "Transaction Dataframe Top 5 Rows :- \n",
      "    TransactionID TransactionDate  UserID  ProductID  Quantity\n",
      "0              1      2010-08-21     7.0          2         1\n",
      "1              2      2011-05-26     3.0          4         1\n",
      "2              3      2011-06-16     3.0          3         1\n",
      "3              4      2012-08-26     1.0          2         3\n",
      "4              5      2013-06-06     2.0          4         1\n",
      "~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~~~*~~\n"
     ]
    }
   ],
   "source": [
    "## Reading Url given in assignments\n",
    "def Print_format():\n",
    "    print (\"~~*~~\"*15)\n",
    "    \n",
    "user_s = pd.read_csv(\"https://raw.githubusercontent.com/ben519/DataWrangling/master/Data/users.csv\")\n",
    "session_s =  pd.read_csv(\"https://raw.githubusercontent.com/ben519/DataWrangling/master/Data/sessions.csv\")\n",
    "product_s = pd.read_csv(\"https://raw.githubusercontent.com/ben519/DataWrangling/master/Data/products.csv\")\n",
    "transaction_s = pd.read_csv(\"https://raw.githubusercontent.com/ben519/DataWrangling/master/Data/transactions.csv\")\n",
    "Print_format()\n",
    "print (\"User Dataframe Top 5 Rows :- \\n\",user_s.head())\n",
    "Print_format()\n",
    "print (\"Session Dataframe Top 5 Rows :- \\n\",session_s.head())\n",
    "Print_format()\n",
    "print (\"Transaction Dataframe Top 5 Rows :- \\n\",transaction_s.head())\n",
    "Print_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TransactionID TransactionDate  UserID  ProductID  Quantity      User  \\\n",
      "0              1      2010-08-21     7.0          2         1       NaN   \n",
      "1              2      2011-05-26     3.0          4         1  Caroline   \n",
      "2              3      2011-06-16     3.0          3         1  Caroline   \n",
      "3              4      2012-08-26     1.0          2         3   Charles   \n",
      "4              5      2013-06-06     2.0          4         1     Pedro   \n",
      "5              6      2013-12-23     2.0          5         6     Pedro   \n",
      "6              7      2013-12-30     3.0          4         1  Caroline   \n",
      "7              8      2014-04-24     NaN          2         3       NaN   \n",
      "8              9      2015-04-24     7.0          4         3       NaN   \n",
      "9             10      2016-05-08     3.0          4         4  Caroline   \n",
      "\n",
      "   Gender  Registered   Cancelled  \n",
      "0     NaN         NaT         NaT  \n",
      "1  female  2012-10-23  2016-06-07  \n",
      "2  female  2012-10-23  2016-06-07  \n",
      "3    male  2012-12-21         NaT  \n",
      "4    male  2010-08-01  2010-08-08  \n",
      "5    male  2010-08-01  2010-08-08  \n",
      "6  female  2012-10-23  2016-06-07  \n",
      "7     NaN         NaT         NaT  \n",
      "8     NaN         NaT         NaT  \n",
      "9  female  2012-10-23  2016-06-07  \n"
     ]
    }
   ],
   "source": [
    "#Join users to transactions, keeping all rows from transactions and only matching rows from users (left join)\n",
    "user_tranaction = transaction_s.merge(user_s,on='UserID',how='left') # left join on userid\n",
    "user_tranaction.Registered.fillna('NaT',inplace=True) # filling Nan with NAt\n",
    "user_tranaction.Cancelled.fillna('NaT',inplace=True)\n",
    "print (user_tranaction) # printed the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TransactionID TransactionDate  UserID  ProductID  Quantity\n",
      "0              1      2010-08-21     7.0          2         1\n",
      "7              8      2014-04-24     NaN          2         3\n",
      "8              9      2015-04-24     7.0          4         3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TransactionID      0\n",
       "TransactionDate    0\n",
       "UserID             1\n",
       "ProductID          0\n",
       "Quantity           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Which transaction have a Userid not in Users ?\n",
    "Only_Nan_User_ = user_tranaction[pd.isnull(user_tranaction['User'])] # Created new df\n",
    "\n",
    "Only_Nan_User_ = Only_Nan_User_[['TransactionID','TransactionDate','UserID','ProductID','Quantity']] # filter colummns\n",
    "print (Only_Nan_User_) # result printed\n",
    "Only_Nan_User_.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TransactionID TransactionDate  UserID  ProductID  Quantity      User  \\\n",
      "0              2      2011-05-26       3          4         1  Caroline   \n",
      "1              3      2011-06-16       3          3         1  Caroline   \n",
      "2              7      2013-12-30       3          4         1  Caroline   \n",
      "3             10      2016-05-08       3          4         4  Caroline   \n",
      "4              4      2012-08-26       1          2         3   Charles   \n",
      "5              5      2013-06-06       2          4         1     Pedro   \n",
      "6              6      2013-12-23       2          5         6     Pedro   \n",
      "\n",
      "   Gender  Registered   Cancelled  \n",
      "0  female  2012-10-23  2016-06-07  \n",
      "1  female  2012-10-23  2016-06-07  \n",
      "2  female  2012-10-23  2016-06-07  \n",
      "3  female  2012-10-23  2016-06-07  \n",
      "4    male  2012-12-21         NaN  \n",
      "5    male  2010-08-01  2010-08-08  \n",
      "6    male  2010-08-01  2010-08-08  \n"
     ]
    }
   ],
   "source": [
    "# Join users to tranactions, keeping only rows from transactions and users that match via UserID (inner join)\n",
    "user_tranaction_2 = transaction_s.merge(user_s,on='UserID',how='inner')\n",
    "user_tranaction_2.Registered.fillna('NaT',inplace=True)\n",
    "user_tranaction_2.UserID = user_tranaction_2.UserID.astype(np.int64)\n",
    "print (user_tranaction_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    TransactionID TransactionDate  UserID  ProductID  Quantity      User  \\\n",
      "0             1.0      2010-08-21     7.0        2.0       1.0       NaN   \n",
      "1             9.0      2015-04-24     7.0        4.0       3.0       NaN   \n",
      "2             2.0      2011-05-26     3.0        4.0       1.0  Caroline   \n",
      "3             3.0      2011-06-16     3.0        3.0       1.0  Caroline   \n",
      "4             7.0      2013-12-30     3.0        4.0       1.0  Caroline   \n",
      "5            10.0      2016-05-08     3.0        4.0       4.0  Caroline   \n",
      "6             4.0      2012-08-26     1.0        2.0       3.0   Charles   \n",
      "7             5.0      2013-06-06     2.0        4.0       1.0     Pedro   \n",
      "8             6.0      2013-12-23     2.0        5.0       6.0     Pedro   \n",
      "9             8.0      2014-04-24     NaN        2.0       3.0       NaN   \n",
      "10            NaN             NaN     4.0        NaN       NaN   Brielle   \n",
      "11            NaN             NaN     5.0        NaN       NaN  Benjamin   \n",
      "\n",
      "    Gender  Registered   Cancelled  \n",
      "0      NaN         NaT         NaT  \n",
      "1      NaN         NaT         NaT  \n",
      "2   female  2012-10-23  2016-06-07  \n",
      "3   female  2012-10-23  2016-06-07  \n",
      "4   female  2012-10-23  2016-06-07  \n",
      "5   female  2012-10-23  2016-06-07  \n",
      "6     male  2012-12-21         NaT  \n",
      "7     male  2010-08-01  2010-08-08  \n",
      "8     male  2010-08-01  2010-08-08  \n",
      "9      NaN         NaT         NaT  \n",
      "10  female  2013-07-17         NaT  \n",
      "11    male  2010-11-25         NaT  \n"
     ]
    }
   ],
   "source": [
    "## Join Users to transactions, displaying all matching rows and all non matching row (ful outer join)\n",
    "user_tranaction_3 = transaction_s.merge(user_s,on='UserID',how='outer')\n",
    "user_tranaction_3.Registered.fillna('NaT',inplace=True)\n",
    "user_tranaction_3.Cancelled.fillna('NaT',inplace=True)\n",
    "print (user_tranaction_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['UserID', 'User', 'Gender', 'Registered', 'Cancelled'], dtype='object')\n",
      "Index(['ProductID', 'Product', 'Price'], dtype='object')\n",
      "5 5\n"
     ]
    }
   ],
   "source": [
    "## Build a Data Set with every possible (UserID and ProductID ) pair (Cross Join)\n",
    "print (user_s.columns)\n",
    "print (product_s.columns)\n",
    "print  (len(user_s),len(product_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>User</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Registered</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>TransactionDate</th>\n",
       "      <th>Quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Charles</td>\n",
       "      <td>male</td>\n",
       "      <td>2012-12-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Pedro</td>\n",
       "      <td>male</td>\n",
       "      <td>2010-08-01</td>\n",
       "      <td>2010-08-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Caroline</td>\n",
       "      <td>female</td>\n",
       "      <td>2012-10-23</td>\n",
       "      <td>2016-06-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Brielle</td>\n",
       "      <td>female</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Benjamin</td>\n",
       "      <td>male</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>14.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B</td>\n",
       "      <td>33.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>C</td>\n",
       "      <td>10.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>D</td>\n",
       "      <td>10.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>E</td>\n",
       "      <td>29.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010-08-21</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2011-05-26</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2011-06-16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2012-08-26</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2013-06-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2013-12-23</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2013-12-30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2014-04-24</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2015-04-24</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2016-05-08</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID      User  Gender  Registered   Cancelled  ProductID Product  Price  \\\n",
       "0     1.0   Charles    male  2012-12-21         NaN        NaN     NaN    NaN   \n",
       "1     2.0     Pedro    male  2010-08-01  2010-08-08        NaN     NaN    NaN   \n",
       "2     3.0  Caroline  female  2012-10-23  2016-06-07        NaN     NaN    NaN   \n",
       "3     4.0   Brielle  female  2013-07-17         NaN        NaN     NaN    NaN   \n",
       "4     5.0  Benjamin    male  2010-11-25         NaN        NaN     NaN    NaN   \n",
       "0     NaN       NaN     NaN         NaN         NaN        1.0       A  14.16   \n",
       "1     NaN       NaN     NaN         NaN         NaN        2.0       B  33.04   \n",
       "2     NaN       NaN     NaN         NaN         NaN        3.0       C  10.65   \n",
       "3     NaN       NaN     NaN         NaN         NaN        4.0       D  10.02   \n",
       "4     NaN       NaN     NaN         NaN         NaN        5.0       E  29.66   \n",
       "0     7.0       NaN     NaN         NaN         NaN        2.0     NaN    NaN   \n",
       "1     3.0       NaN     NaN         NaN         NaN        4.0     NaN    NaN   \n",
       "2     3.0       NaN     NaN         NaN         NaN        3.0     NaN    NaN   \n",
       "3     1.0       NaN     NaN         NaN         NaN        2.0     NaN    NaN   \n",
       "4     2.0       NaN     NaN         NaN         NaN        4.0     NaN    NaN   \n",
       "5     2.0       NaN     NaN         NaN         NaN        5.0     NaN    NaN   \n",
       "6     3.0       NaN     NaN         NaN         NaN        4.0     NaN    NaN   \n",
       "7     NaN       NaN     NaN         NaN         NaN        2.0     NaN    NaN   \n",
       "8     7.0       NaN     NaN         NaN         NaN        4.0     NaN    NaN   \n",
       "9     3.0       NaN     NaN         NaN         NaN        4.0     NaN    NaN   \n",
       "\n",
       "   TransactionID TransactionDate  Quantity  \n",
       "0            NaN             NaN       NaN  \n",
       "1            NaN             NaN       NaN  \n",
       "2            NaN             NaN       NaN  \n",
       "3            NaN             NaN       NaN  \n",
       "4            NaN             NaN       NaN  \n",
       "0            NaN             NaN       NaN  \n",
       "1            NaN             NaN       NaN  \n",
       "2            NaN             NaN       NaN  \n",
       "3            NaN             NaN       NaN  \n",
       "4            NaN             NaN       NaN  \n",
       "0            1.0      2010-08-21       1.0  \n",
       "1            2.0      2011-05-26       1.0  \n",
       "2            3.0      2011-06-16       1.0  \n",
       "3            4.0      2012-08-26       3.0  \n",
       "4            5.0      2013-06-06       1.0  \n",
       "5            6.0      2013-12-23       6.0  \n",
       "6            7.0      2013-12-30       1.0  \n",
       "7            8.0      2014-04-24       3.0  \n",
       "8            9.0      2015-04-24       3.0  \n",
       "9           10.0      2016-05-08       4.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cross_row = pd.concat([user_s,product_s,transaction_s], axis=0, sort=False) # This is One Method with Axis and Concatination with row wise\n",
    "df_cross_row # This is not the answere as expected out put"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>User</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Registered</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>TransactionDate</th>\n",
       "      <th>UserID</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>Quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Charles</td>\n",
       "      <td>male</td>\n",
       "      <td>2012-12-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>14.16</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-08-21</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Pedro</td>\n",
       "      <td>male</td>\n",
       "      <td>2010-08-01</td>\n",
       "      <td>2010-08-08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B</td>\n",
       "      <td>33.04</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-05-26</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Caroline</td>\n",
       "      <td>female</td>\n",
       "      <td>2012-10-23</td>\n",
       "      <td>2016-06-07</td>\n",
       "      <td>3.0</td>\n",
       "      <td>C</td>\n",
       "      <td>10.65</td>\n",
       "      <td>3</td>\n",
       "      <td>2011-06-16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Brielle</td>\n",
       "      <td>female</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>D</td>\n",
       "      <td>10.02</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-08-26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Benjamin</td>\n",
       "      <td>male</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>E</td>\n",
       "      <td>29.66</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-06-06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>2013-12-23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>2013-12-30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2014-04-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>2015-04-24</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2016-05-08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID      User  Gender  Registered   Cancelled  ProductID Product  Price  \\\n",
       "0     1.0   Charles    male  2012-12-21         NaN        1.0       A  14.16   \n",
       "1     2.0     Pedro    male  2010-08-01  2010-08-08        2.0       B  33.04   \n",
       "2     3.0  Caroline  female  2012-10-23  2016-06-07        3.0       C  10.65   \n",
       "3     4.0   Brielle  female  2013-07-17         NaN        4.0       D  10.02   \n",
       "4     5.0  Benjamin    male  2010-11-25         NaN        5.0       E  29.66   \n",
       "5     NaN       NaN     NaN         NaN         NaN        NaN     NaN    NaN   \n",
       "6     NaN       NaN     NaN         NaN         NaN        NaN     NaN    NaN   \n",
       "7     NaN       NaN     NaN         NaN         NaN        NaN     NaN    NaN   \n",
       "8     NaN       NaN     NaN         NaN         NaN        NaN     NaN    NaN   \n",
       "9     NaN       NaN     NaN         NaN         NaN        NaN     NaN    NaN   \n",
       "\n",
       "   TransactionID TransactionDate  UserID  ProductID  Quantity  \n",
       "0              1      2010-08-21     7.0          2         1  \n",
       "1              2      2011-05-26     3.0          4         1  \n",
       "2              3      2011-06-16     3.0          3         1  \n",
       "3              4      2012-08-26     1.0          2         3  \n",
       "4              5      2013-06-06     2.0          4         1  \n",
       "5              6      2013-12-23     2.0          5         6  \n",
       "6              7      2013-12-30     3.0          4         1  \n",
       "7              8      2014-04-24     NaN          2         3  \n",
       "8              9      2015-04-24     7.0          4         3  \n",
       "9             10      2016-05-08     3.0          4         4  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cross_column = pd.concat([user_s,product_s,transaction_s], axis=1, sort=False) # This is One Method with Axis and Concatination with columns\n",
    "df_cross_column # Same here is This not the expceted answere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>User</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Registered</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Charles</td>\n",
       "      <td>male</td>\n",
       "      <td>2012-12-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>14.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pedro</td>\n",
       "      <td>male</td>\n",
       "      <td>2010-08-01</td>\n",
       "      <td>2010-08-08</td>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>33.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Caroline</td>\n",
       "      <td>female</td>\n",
       "      <td>2012-10-23</td>\n",
       "      <td>2016-06-07</td>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "      <td>10.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Brielle</td>\n",
       "      <td>female</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>D</td>\n",
       "      <td>10.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Benjamin</td>\n",
       "      <td>male</td>\n",
       "      <td>2010-11-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>E</td>\n",
       "      <td>29.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID      User  Gender  Registered   Cancelled  ProductID Product  Price\n",
       "0       1   Charles    male  2012-12-21         NaN          1       A  14.16\n",
       "1       2     Pedro    male  2010-08-01  2010-08-08          2       B  33.04\n",
       "2       3  Caroline  female  2012-10-23  2016-06-07          3       C  10.65\n",
       "3       4   Brielle  female  2013-07-17         NaN          4       D  10.02\n",
       "4       5  Benjamin    male  2010-11-25         NaN          5       E  29.66"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Merge = pd.merge(user_s, product_s,  how='left', left_on=['UserID'], right_on = ['ProductID'])\n",
    "df_Merge # same as above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ProductID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    UserID  ProductID\n",
       "0        1          1\n",
       "1        1          2\n",
       "2        1          3\n",
       "3        1          4\n",
       "4        1          5\n",
       "5        2          1\n",
       "6        2          2\n",
       "7        2          3\n",
       "8        2          4\n",
       "9        2          5\n",
       "10       3          1\n",
       "11       3          2\n",
       "12       3          3\n",
       "13       3          4\n",
       "14       3          5\n",
       "15       4          1\n",
       "16       4          2\n",
       "17       4          3\n",
       "18       4          4\n",
       "19       4          5\n",
       "20       5          1\n",
       "21       5          2\n",
       "22       5          3\n",
       "23       5          4\n",
       "24       5          5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Build a Data Set with every possible (UserID and ProductID ) pair (Cross Join) \n",
    "## Here !!! We Go with this solution \n",
    "get_index_level = pd.MultiIndex.from_product([user_s.UserID, product_s.ProductID], names = [\"UserID\", \"ProductID\"]) \n",
    "# Created Level as per item present in both feilds\n",
    "expected_result = pd.DataFrame(index = get_index_level).reset_index() \n",
    "# level reseted and from the data frame as expected (cartesian product)\n",
    "expected_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    UserID  ProductID  Quantity\n",
      "0        1          1       0.0\n",
      "1        1          2       3.0\n",
      "2        1          3       0.0\n",
      "3        1          4       0.0\n",
      "4        1          5       0.0\n",
      "5        2          1       0.0\n",
      "6        2          2       0.0\n",
      "7        2          3       0.0\n",
      "8        2          4       1.0\n",
      "9        2          5       6.0\n",
      "10       3          1       0.0\n",
      "11       3          2       0.0\n",
      "12       3          3       1.0\n",
      "13       3          4       1.0\n",
      "14       3          4       1.0\n",
      "15       3          4       4.0\n",
      "16       3          5       0.0\n",
      "17       4          1       0.0\n",
      "18       4          2       0.0\n",
      "19       4          3       0.0\n",
      "20       4          4       0.0\n",
      "21       4          5       0.0\n",
      "22       5          1       0.0\n",
      "23       5          2       0.0\n",
      "24       5          3       0.0\n",
      "25       5          4       0.0\n",
      "26       5          5       0.0\n"
     ]
    }
   ],
   "source": [
    "# Determine how much quantity of each product was purchased by each user\n",
    "\n",
    "user_product_Transdf = pd.merge(expected_result, transaction_s, how='left', on=['UserID','ProductID'])\n",
    "#print(user_product_Transdf) #Print the joined dataframe result\n",
    "user_product_TransdfResult = user_product_Transdf.drop(['TransactionID', 'TransactionDate'], axis=1)\n",
    "\n",
    "\n",
    "#Drop the unwanted column from the result dataframe and set to a new dataframe\n",
    "user_product_TransdfResult1 = user_product_TransdfResult.fillna(0)\n",
    "\n",
    "print(user_product_TransdfResult1) # Print the fnal result\n",
    " # Print the fnal result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    TransactionID_x TransactionDate_x  UserID  ProductID_x  Quantity_x  \\\n",
      "0                 1        2010-08-21     7.0            2           1   \n",
      "1                 1        2010-08-21     7.0            2           1   \n",
      "21                9        2015-04-24     7.0            4           3   \n",
      "20                9        2015-04-24     7.0            4           3   \n",
      "24               10        2016-05-08     3.0            4           4   \n",
      "23               10        2016-05-08     3.0            4           4   \n",
      "22               10        2016-05-08     3.0            4           4   \n",
      "18                7        2013-12-30     3.0            4           1   \n",
      "17                7        2013-12-30     3.0            4           1   \n",
      "16                7        2013-12-30     3.0            4           1   \n",
      "\n",
      "    TransactionID_y TransactionDate_y  ProductID_y  Quantity_y  \n",
      "0                 1        2010-08-21            2           1  \n",
      "1                 9        2015-04-24            4           3  \n",
      "21                9        2015-04-24            4           3  \n",
      "20                1        2010-08-21            2           1  \n",
      "24                7        2013-12-30            4           1  \n",
      "23                3        2011-06-16            3           1  \n",
      "22                2        2011-05-26            4           1  \n",
      "18               10        2016-05-08            4           4  \n",
      "17                7        2013-12-30            4           1  \n",
      "16                3        2011-06-16            3           1  \n"
     ]
    }
   ],
   "source": [
    "##For each user, get each possible pair of pair transactions (TransactionID1, TransacationID2)\n",
    "transactions1 = transaction_s.drop(['UserID'], axis=1) # drop on columns\n",
    "pair_Of_Transdf = pd.merge(transaction_s, transaction_s, how='left',   on=['UserID']) # left join orginal with new\n",
    "\n",
    "print(pair_Of_Transdf.sort_values(by=['UserID'],ascending=[False]).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserID      User  Gender  Registered   Cancelled  TransactionID  ProductID  \\\n",
      "0       1   Charles    male  2012-12-21         NaN            4.0        2.0   \n",
      "1       2     Pedro    male  2010-08-01  2010-08-08            5.0        4.0   \n",
      "2       3  Caroline  female  2012-10-23  2016-06-07            2.0        4.0   \n",
      "3       4   Brielle  female  2013-07-17         NaN            NaN        NaN   \n",
      "4       5  Benjamin    male  2010-11-25         NaN            NaN        NaN   \n",
      "\n",
      "   Quantity  \n",
      "0       3.0  \n",
      "1       1.0  \n",
      "2       1.0  \n",
      "3       NaN  \n",
      "4       NaN  \n"
     ]
    }
   ],
   "source": [
    "# Join each user to his/her first occuring transaction in the transactions table\n",
    "# first select the first transaction for each user\n",
    "firstOccur_transactions = transaction_s.groupby('UserID').first().reset_index()\n",
    "\n",
    "#drop the unwanted column(s)\n",
    "firstOccur_transactions = firstOccur_transactions.drop(['TransactionDate'], axis=1)\n",
    "\n",
    "first_Occur_transactions_By_Each_User = pd.merge(user_s, firstOccur_transactions, how='left', on=['UserID'])\n",
    "print(first_Occur_transactions_By_Each_User)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>User</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Registered</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>SessionID</th>\n",
       "      <th>SessionDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Pedro</td>\n",
       "      <td>male</td>\n",
       "      <td>2010-08-01</td>\n",
       "      <td>2010-08-08</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Brielle</td>\n",
       "      <td>female</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>2013-07-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID     User  Gender  Registered   Cancelled  SessionID SessionDate\n",
       "0       2    Pedro    male  2010-08-01  2010-08-08          2  2010-08-01\n",
       "1       4  Brielle  female  2013-07-17         NaN          9  2013-07-17"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine which sessions occurred on the same day each user registered \n",
    "pd.merge(left=user_s, right=session_s, how='inner', left_on=['UserID', 'Registered'], right_on=['UserID', 'SessionDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cancelled', 'TransactionID', 'ProductID', 'Quantity']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test to see if we can drop columns\n",
    "data_new_each_user = first_Occur_transactions_By_Each_User\n",
    "my_columns = list(data_new_each_user.columns)\n",
    "my_columns\n",
    "['UserID',\n",
    "'User',\n",
    "'Gender',\n",
    "'Registered',\n",
    "'Cancelled',\n",
    "'TransactionID',\n",
    "'TransactionDate',\n",
    "'ProductID',\n",
    "'Quantity']\n",
    "list(data_new_each_user.dropna(thresh=int(data_new_each_user.shape[0] * .9), axis=1).columns) #set threshold to drop NAs\n",
    "['UserID', 'User', 'Gender', 'Registered']\n",
    "missing_info = list(data_new_each_user.columns[data_new_each_user.isnull().any()])\n",
    "missing_info ## Data Where the values are missing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*\n",
      "number missing for column Cancelled: 3\n",
      "number missing for column Cancelled: 60.0% .\n",
      "~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*\n",
      "~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*\n",
      "number missing for column TransactionID: 2\n",
      "number missing for column TransactionID: 40.0% .\n",
      "~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*\n",
      "~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*\n",
      "number missing for column ProductID: 2\n",
      "number missing for column ProductID: 40.0% .\n",
      "~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*\n",
      "~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*\n",
      "number missing for column Quantity: 2\n",
      "number missing for column Quantity: 40.0% .\n",
      "~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*\n"
     ]
    }
   ],
   "source": [
    "## NOTE : TransactionDate having no null values so program result vary with acutal example provided in question\n",
    "for col in missing_info: # How many values are missed in columns as well as count\n",
    "        print (\"~*~*\"*8)\n",
    "        num_missing = data_new_each_user[data_new_each_user[col].isnull() == True].shape[0]\n",
    "        print('number missing for column {}: {}'.format(col, num_missing))\n",
    "        percent_missing = data_new_each_user[data_new_each_user[col].isnull() == True].shape[0] / len(data_new_each_user[col])\n",
    "        print('number missing for column {}: {}% .'.format(col, percent_missing*100))\n",
    "        print (\"~*~*\"*8)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
